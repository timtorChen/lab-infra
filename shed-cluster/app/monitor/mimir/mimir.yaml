---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  # disable flux env substitute and use config expand
  labels:
    kustomize.toolkit.fluxcd.io/substitute: disabled
  namespace: monitor
  name: mimir
spec:
  chart:
    spec:
      sourceRef:
        kind: HelmRepository
        namespace: flux-system
        name: grafana
      # renovate: registryUrl=https://grafana.github.io/helm-charts
      chart: mimir-distributed
      version: 2.2.0-weekly.190
  interval: 1h
  values:
    minio:
      enabled: false
    nginx:
      enabled: false

    image:
      repository: grafana/mimir
      tag: 2.1.0

    global:
      extraEnvFrom:
        - secretRef:
            name: mimir-secret

    # -- Secret typed configs
    # check the environment documentation:
    # https://github.com/grafana/mimir/blob/main/docs/sources/operators-guide/configuring/reference-configuration-parameters/index.md
    mimir:
      config: |
        multitenancy_enabled: true

        # tanent limit
        limits: {}

        activity_tracker:
          filepath: /data/metrics-activity.log

        server:
          grpc_server_max_recv_msg_size: 104857600
          grpc_server_max_send_msg_size: 104857600
          grpc_server_max_concurrent_streams: 1000

        # components will find each other with the gossip-ring service
        memberlist:
          abort_if_cluster_join_fails: false
          compression_enabled: false
          join_members:
          - mimir-gossip-ring

        frontend:
          log_queries_longer_than: 10s
          align_queries_with_step: true

        frontend_worker:
          frontend_address: mimir-query-frontend-headless:9095

        ingester:
          ring:
            final_sleep: 0s
            num_tokens: 512

        ingester_client:
          grpc_client_config:
            max_recv_msg_size: 104857600
            max_send_msg_size: 104857600

        compactor:
          data_dir: /data

        blocks_storage:
          backend: s3
          tsdb:
            dir: /data/tsdb
          bucket_store:
            sync_dir: /data/tsdb-sync
          s3:
            endpoint: minio.minio.svc:9000
            bucket_name: mimir-tsdb
            access_key_id: ${MIMIR_S3_ACCESS_ID}
            secret_access_key: ${MIMIR_S3_ACCESS_KEY}
            insecure: true

    # -- Read Workload
    # query_frontend, stateless
    query_frontend:
      replicas: 1
      resources:
        requests:
          cpu: 100m
          memory: 128Mi
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 1
          maxUnavailable: 0
      readinessProbe:
        initialDelaySeconds: 20
    # querier, stateless
    querier:
      replicas: 1
      resources:
        requests:
          cpu: 100m
          memory: 128Mi
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 1
          maxUnavailable: 0
      initialDelaySeconds: 20
    # store_gateway, stateful
    # index and chunk cache
    store_gateway:
      replicas: 1
      resources:
        requests:
          cpu: 100m
          memory: 128Mi
      # even the data can be redownloaded
      # it is recommanded to give a volume for the cache
      persistentVolume:
        enabled: true
        storageClass: ceph-fs
        size: 1Gi
      readinessProbe:
        initialDelaySeconds: 20
    # -- Write Workload
    # distributor, stateless
    # receive data from prometheus, and divide data to downstream ingesters
    distributor:
      replicas: 1
      resources:
        requests:
          cpu: 100m
          memory: 128Mi
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 1
          maxUnavailable: 0
      readinessProbe:
        initialDelaySeconds: 20
    # ingester, stateful
    # data are stored 2 hours before uploaded to S3
    ingester:
      replicas: 3
      resources:
        requests:
          cpu: 100m
          memory: 128Mi
      persistentVolume:
        enabled: true
        storageClass: ceph-fs
        size: 2Gi
      readinessProbe:
        initialDelaySeconds: 20
    # compactor, stateful
    # merge 2 hrs period blocks into one block,
    # and compact mutiple period blocks to a large block
    compactor:
      replicas: 1
      resources:
        requests:
          cpu: 100m
          memory: 128Mi
      # compactor storage is used for blocks download
      # for a light usage data is quiet small, and it's fine to redownload
      persistentVolume:
        enabled: false
      readinessProbe:
        initialDelaySeconds: 20
    ruler:
      enabled: false
    alertmanager:
      enabled: false
    overrides_exporter:
      enabled: false
